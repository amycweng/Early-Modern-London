{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c71dbcb",
   "metadata": {},
   "source": [
    "Named entity recognition (NER) using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9417b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "# For first time downloading: \n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b790288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text info into a dictionary with keys as the file name. \n",
    "# Automatically breaks texts that are longer than 1 million words into two separate dictionary entries (assumes that the total size is less than 2m words)\n",
    "def getTexts(folder):\n",
    "    texts = {}\n",
    "    for file in os.listdir(folder):\n",
    "        if 'NOTES' not in file: \n",
    "            name = file.split('.')[0]\n",
    "            path = os.path.join(folder,file)\n",
    "            with open(path,'r') as file: \n",
    "                data = file.readlines()\n",
    "            if len(data) != 0: \n",
    "                text = data[0].split(' ')\n",
    "                length = len(text)\n",
    "                if length > 1000000: \n",
    "                    texts[f'{name}_part1'] = ' '.join(text[:length/2])\n",
    "                    texts[f'{name}_part2'] = ' '.join(text[length/2:])\n",
    "                else: \n",
    "                    texts[name] = ' '.join(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bd5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "playFiles = getTexts('/Users/amycweng/Digital Humanities/Early-Modern-London/playPartsTXT')\n",
    "print(len(playFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf180880",
   "metadata": {},
   "outputs": [],
   "source": [
    "charityTexts = getTexts('/Users/amycweng/Digital Humanities/charityTXT')\n",
    "print(len(charityTexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507b3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running named entity recognition using spaCy\n",
    "allEnts = []\n",
    "ner = spacy.load('en_core_web_sm')\n",
    "count = 0\n",
    "for name, text in playFiles.items():\n",
    "    count += 1\n",
    "    if not count % 40: print(f'processed {count} so far')\n",
    "    entities = ner(text)\n",
    "    for ent in entities.ents:\n",
    "        allEnts.append(str(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "allEntities = []\n",
    "for ent in allEnts: \n",
    "    allEntities.append(str(ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(allEntities)\n",
    "print(counts.most_common(n=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34937707",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/amycweng/Digital Humanities/Early-Modern-London/Other_Files/playsNER.txt','w+') as file: \n",
    "    file.write(str(counts.most_common(n=10000000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "60b55922",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences = []\n",
    "for name, text in charityTexts.items():\n",
    "    important = []\n",
    "    words = text.split(' ')\n",
    "    for idx, word in enumerate(words):\n",
    "        if re.search('charity',word): \n",
    "            phrase = ' '.join(words[idx-20:idx+20])\n",
    "            occurrences.append(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8c81ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anachoret the worst of all prisoner there sit he pen up for his further merit half hunger starved for the charity of the citizen it be worth see how manly he can bite in his secret want and dissemble his\n",
      "correspondence between heaven and earth the present happiness of those heavenly citizen can have abate aught of their knowledge and charity but must needs have raise they to a high pitch of both they therefore who be now glorious comprehensor\n",
      "correspondence between heaven and earth the present happiness of those heavenly citizen can have abate aught of their knowledge and charity but must needs have raise they to a high pitch of both they therefore who be now glorious comprehensor\n",
      "anachoret the worst of all prisoner there sit he pent up for his further merit half hunger starved for the charity of the citizen it be worth see how manly he can bite in his secret want and dissemble his\n"
     ]
    }
   ],
   "source": [
    "for phrase in occurrences: \n",
    "    if 'citizen' in phrase: \n",
    "        print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2cf21b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^citizen$|^livery$|^alderman$|^pilgrim$|^window$|^shop$|^chamber$|^bridge$|^wall$|^st paul$|^westminster$|^thames$|^river$|^sea$|^channel$|^pond$|^temple$|^city$|^village$|^province$|^town$|^house$|^inn$|^market$|^gate$|^cheapside$|^bishopsgate$|^southwark$|^cornhill$|^tavern$|^hall$|^chapel$|^england$|^hospital$|^tower$|^gallow$|^neighbourhood$|^parish$|^suburb$|^manor$|^prison$|^playhouse$|^church$|^churchyard$|^alley$|^whitechapel$|^shire$|^london$'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = ['citizen','livery','alderman','pilgrim',\n",
    "'window','shop','chamber','bridge',\n",
    "'wall','st paul','westminster','thames',\n",
    "'river','sea','channel','pond','temple',\n",
    "'city','village','province','town',\n",
    "'house','inn','market','gate',\n",
    "'cheapside','bishopsgate','southwark',\n",
    "'cornhill','tavern','hall','chapel',\n",
    "'england','hospital','tower','gallow',\n",
    "'neighbourhood','parish','suburb',\n",
    "'manor','prison','playhouse','church','churchyard',\n",
    "'alley','whitechapel','shire','london']\n",
    "for idx in range(len(places)): \n",
    "    places[idx] = f'^{places[idx]}$'\n",
    "place_search = '|'.join(places)\n",
    "place_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c57ced85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'^charity$|^charitable$|^alm$|^bequest$|^poor$|^rate$|^usury$|^usurer$|^give$|^bequeath$|^help$|^money$|^beneficence$|^poverty$|^credit$|^creditor$|^loan$|^lend$|^new$|^novel$|^novelty$|^wealth$|^profit$|^profitable$|^beneficial$|^commodity$|^thrift$|^thrifty$|^industry$|^bullion$'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['charity','charitable','alm','bequest',\n",
    "        'poor','rate','usury','usurer','give','bequeath',\n",
    "        'help','money','beneficence','poverty','credit',\n",
    "        'creditor','loan','lend','new','novel','novelty',\n",
    "        'wealth','profit','profitable','beneficial',\n",
    "        'commodity','thrift','thrifty','industry','bullion']\n",
    "for idx in range(len(words)): \n",
    "    words[idx] = f'^{words[idx]}$'\n",
    "words_search = '|'.join(words)\n",
    "words_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d17fb5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter()\n"
     ]
    }
   ],
   "source": [
    "hits = []\n",
    "important = []\n",
    "for name, text in charityTexts.items():\n",
    "    text = text.split(' ')\n",
    "    for idx, word in enumerate(text):\n",
    "            if re.search(words_search,word):  \n",
    "                phrase = ' '.join(text[idx-40:idx+40])\n",
    "                if re.search(place_search,phrase):\n",
    "                    hits.append(word)\n",
    "                    print(phrase)\n",
    "                    break\n",
    "                    important.append(phrase)\n",
    "    break\n",
    "    if len(important) > 0: \n",
    "        print(name,important)\n",
    "# print(Counter(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fd016e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1adee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "for name, text in playFiles.items():\n",
    "    important = []\n",
    "    words = text.split(' ')\n",
    "    for idx, word in enumerate(words):\n",
    "        if re.search('credit',word): \n",
    "            phrase = ' '.join(words[idx-5:idx+5])\n",
    "            important.append(phrase)\n",
    "    if len(important) > 0: \n",
    "        print(name,important)\n",
    "            # places.append()  \n",
    "# print(Counter(places))\n",
    "# print(places)\n",
    "# for place in places: \n",
    "#     print(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# places = []\n",
    "for name, text in playFiles.items():\n",
    "    important = []\n",
    "    words = text.split(' ')\n",
    "    for idx, word in enumerate(words):\n",
    "        if re.search('credit|bullion|money|^monie|profit|^wealth|merit|industry|loan|lend|^commodit|thrift|charit|',word): \n",
    "            phrase = ' '.join(words[idx-10:idx+10])\n",
    "            if re.search('london|city|cittie|westminster|cheapside|church|southwark|alley|whitechapel|street|shire$|avenue|place|^inn$|bridge',phrase):\n",
    "                important.append(phrase)\n",
    "    if len(important) > 0: \n",
    "        print(name,important)\n",
    "            # places.append()  \n",
    "# print(Counter(places))\n",
    "# print(places)\n",
    "# for place in places: \n",
    "#     print(place)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
