{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getTexts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Separately extract each act of a play as a TXT file. \n",
    "\n",
    "NOTE: For EP XML files that contain only one play  \n",
    "'''\n",
    "def writeToFile(bodytext,folder,tcpID,head):\n",
    "    with open(f'{folder}/{tcpID}_{head}.txt', 'w+') as file:\n",
    "        bodytext = replaceTextLemma(bodytext,lemmaDict)\n",
    "        cleaned = cleanText(bodytext)\n",
    "        cleaned = cleaned.replace('\\n',' ')\n",
    "        file.write(f'{cleaned}') \n",
    "\n",
    "def extractActs(tcpID,folder):\n",
    "    getActs = True\n",
    "    path,source = findText(tcpID,getActs)\n",
    "    with open(path,'r') as file: \n",
    "        data = file.read()\n",
    "    targetTag = SoupStrainer(\"div\",attrs={\"type\":\"act\"})\n",
    "    soup = BeautifulSoup(data,parse_only=targetTag,features='html.parser')\n",
    "    acts = soup.find_all('div',attrs={\"type\":\"act\"})\n",
    "    for idx,act in enumerate(acts): \n",
    "        head = f'Act {idx+1}' \n",
    "        bodytext = textEP(act).lower()\n",
    "        writeToFile(folder,tcpID,head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Ids for the plays in Sarah's spreadsheet   \n",
    "'''\n",
    "tcpIDs = ['A03208', # If You Know Not Me \n",
    "        'A03197', # Fair Maid of the Exchange\n",
    "        'A20100', # Westward Ho\n",
    "        'A07493', # Chaste Maid \n",
    "        'A04633_03', # Staple of News \n",
    "        'A11153', # A New Wonder \n",
    "        'A18407', # Eastward Ho\n",
    "        'A19260', # Greene's Tu Quoque \n",
    "        'A07524', # The Roaring Girl \n",
    "        'A07505', # Michaelmas Term \n",
    "        'A04648', # Every Man Out of His Humour \n",
    "        'A11146', # When You See Me \n",
    "        'A20083', # The Shoemaker's Holiday\n",
    "        'A20098', # Northward Ho\n",
    "        'A07065', # The Dutch Courtesan\n",
    "        'A07025', # Holland's Leaguer \n",
    "        'A02092', # A Disputation Between \n",
    "        'A03224', # Edward IV \n",
    "        'A12078', # The Fleire \n",
    "        'A18427', # The Ball\n",
    "        'A12142', # The Lady of Pleasure\n",
    "        'A77565_04', # The City Wit \n",
    "        'A77567_04', # The New Academy \n",
    "        'A53070_02', # The Variety \n",
    "        'A46228', # The Devil is an Ass \n",
    "        'A59985', # The School of Complement \n",
    "        'A04645', # Epicoene \n",
    "        'A12140', # Hyde Park \n",
    "        'A06252' # The Knight of the Burning Pestle \n",
    "        ]\n",
    "outputfolder = 'playPartsTXT'\n",
    "folder = f'/Users/amycweng/Digital Humanities/{outputfolder}'\n",
    "for tcpID in tcpIDs: \n",
    "    extractActs(tcpID,folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract the entire body text from an XML document.  \n",
    "'''\n",
    "# getting the plays in Sarah's spreadsheet \n",
    "getNotes = False\n",
    "outputfolder = 'playsTXT'\n",
    "convert(tcpIDs,getNotes,outputfolder)\n",
    "print(underscores)\n",
    "convert(underscores,getNotes,outputfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A21218 is not in EP\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Extract a particular English section from a TCP document with many languages and/or works \n",
    "'''\n",
    "outputfolder = 'playPartsTXT'\n",
    "folder = f'/Users/amycweng/Digital Humanities/{outputfolder}'\n",
    "tcpID = 'A21218' # Bilingual version of Ortho-epia Gallica\n",
    "# Want John Eliot's Parlement of Pratlers \n",
    "# Can only find the conclusion in English under a HEAD tag \n",
    "\n",
    "''' \n",
    "NOTE: Once you have found your target section under a tag in a TCP xml file, \n",
    "move the </HEAD> concluding tag to the bottom of the section. \n",
    "That way, only the target section has the associated text, not just the heading title \n",
    "\n",
    "Outputs the body text of a particular section to a TXT file. \n",
    "Names each TXT file by the {tcpID}_{section heading}\n",
    "'''\n",
    "def partialTextTCP(soup,target):\n",
    "    text_list = []\n",
    "    headings = soup.find_all('head')\n",
    "    for tag in headings:\n",
    "        children = tag.children\n",
    "        if target in tag.text: \n",
    "            for child in children:\n",
    "                text_list.append(child.text.strip())\n",
    "    return ' '.join(text_list[1:])\n",
    "\n",
    "head = 'The Conclusion of the Parlement of Pratlers.'\n",
    "path,source = '/Users/amycweng/Digital Humanities/editedA21218.P4.xml','TCP'\n",
    "with open(path,'r') as file: \n",
    "    data = file.read()\n",
    "targetTag = SoupStrainer(\"div3\",attrs={\"lang\": \"eng\"})\n",
    "soup = BeautifulSoup(data,parse_only=targetTag,features='html.parser')\n",
    "\n",
    "if source == 'TCP': \n",
    "    print(f'{tcpID} is not in EP')\n",
    "    bodytext = partialTextTCP(soup,head).lower()\n",
    "    writeToFile(bodytext,folder,tcpID,head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Extract a particular play from an EP xml version of an anthology \n",
    "\n",
    "The trick is to manually identify the section of the XML\n",
    "and then add the <play>... </play> tag to the beginning and end of the section. \n",
    "'''\n",
    "outputfolder = 'playPartsTXT'\n",
    "folder = f'/Users/amycweng/Digital Humanities/{outputfolder}'\n",
    "tcpID = 'A53060' # Margaret Cavendish's The Female Academy \n",
    "title = 'The Female Academy'\n",
    "path = '/Users/amycweng/Digital Humanities/editedA53060.xml'\n",
    "with open(path,'r') as file: \n",
    "    data = file.read()\n",
    "targetTag = SoupStrainer(\"play\")\n",
    "soup = BeautifulSoup(data,parse_only=targetTag,features='html.parser')\n",
    "\n",
    "'''\n",
    "for extracting particular acts \n",
    "\n",
    "acts = soup.find_all('div',attrs={\"type\":\"act\"})\n",
    "for idx,act in enumerate(acts): \n",
    "    head = f'{title}_Act {idx+1}' \n",
    "    bodytext = textEP(act).lower()\n",
    "    writeToFile(bodytext,folder,tcpID,head)\n",
    "'''\n",
    "\n",
    "''' \n",
    "for extracting the entire body text\n",
    "\n",
    "bodytext = textEP(soup).lower()\n",
    "writeToFile(bodytext,folder,tcpID,title)\n",
    "'''\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
