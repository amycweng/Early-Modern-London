{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Social network visualization \n",
    "'''\n",
    "import re\n",
    "import pandas as pd\n",
    "from pyvis.network import Network\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def authors(csv,search):\n",
    "    '''\n",
    "    Extract text IDs and authors' names.\n",
    "    '''\n",
    "    df = pd.read_csv(csv)\n",
    "    authors = df['author']\n",
    "    ids = df['id']\n",
    "    titles = df['title']\n",
    "    count = 0\n",
    "    dict = {}\n",
    "    for idx,TCPID in enumerate(ids):\n",
    "        if TCPID.strip() in search: \n",
    "            words = authors[idx].split(';')\n",
    "            newWords = []\n",
    "            for w in words: \n",
    "                w = w.strip()\n",
    "                if w == '': continue\n",
    "                if ' aut' in w: w = re.sub(' aut','',w)\n",
    "                if re.search('printer|engraver',w):continue\n",
    "                if re.search('Brome, Richard, d. 1652?|Brome, Ricahrd, d. 1652?.',w):\n",
    "                    # we want to retain the distinction between direct & attributed authorship  \n",
    "                    if 'attributed name.' not in w: \n",
    "                        w = 'Brome, Richard, d. 1652?'\n",
    "                if 'Marston, John, 1575?-1634.' in w: \n",
    "                    if 'attributed name.' not in w: \n",
    "                        w = 'Marston, John, 1575?-1634'\n",
    "                if 'Newcastle, William Cavendish, Duke of, 1592-1676.' in w: \n",
    "                    if 'attributed name.' not in w: \n",
    "                        w='Newcastle, William Cavendish, Duke of, 1592-1676.'\n",
    "                newWords.append(w)\n",
    "            dict[TCPID] = [list(set(newWords)),titles[idx]]\n",
    "            count += 1\n",
    "    return dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "'''Get n-gram features'''\n",
    "inFile = open('/Users/amycweng/Digital Humanities/Early-Modern-London/gramsEachplaysText.txt','r')\n",
    "\n",
    "inFileLines = inFile.readlines()\n",
    "inFile.close()\n",
    "ngrams = {}\n",
    "for line in inFileLines: \n",
    "    line = line.split(':')\n",
    "    tcpID = line[0].strip()\n",
    "    if '_' in tcpID: \n",
    "        tcpID = tcpID.split('_')[0]\n",
    "    features = line[1].strip()\n",
    "    if features == '': continue\n",
    "    allfeatures = features.strip().split(' ')\n",
    "    ngrams[tcpID] = []\n",
    "    for f in allfeatures: \n",
    "        if re.search('thrift|thrifty|commodity|profit|wealth',f): \n",
    "            ngrams[tcpID].append(f)\n",
    "print(len(ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "['Heywood, Thomas, d. 1641.', 'Fletcher, John, 1579-1625.', 'Sharpham, Edward, 1576-1608.', 'Rowley, William, 1585?-1642?', 'Jonson, Ben, 1573?-1637.', 'Greene, Thomas, d. 1612.', 'Shirley, James, 1596-1666.', 'Newcastle, William Cavendish, Duke of, 1592-1676.', 'Brome, Alexander, 1620-1666.', 'Cooke, Jo., fl. 1614.', 'Beaumont, Francis, 1584-1616.', 'Webster, John, 1580?-1625?', 'Rowley, Samuel, d. 1633?', 'Marmion, Shackerley, 1603-1639.', 'Greene, Robert, 1558?-1592.', 'Brome, Richard, d. 1652?', 'Marston, John, 1575?-1634', 'Dekker, Thomas, ca. 1572-1632.', 'Chapman, George, 1559?-1634.', 'Heywood, Thomas, d. 1641, attributed name.', 'Middleton, Thomas, d. 1627.']\n",
      "27\n",
      "['T Gubbin', 'Francis Constable', 'John Oxenbridge', 'Walter Burre', 'William Holme', 'Thomas Dring', 'John Hodgets', 'Hum Robinson', 'A Johnson', 'Humrey Lownes', 'Hum Hoseley', 'John Trundle', 'H Brome', 'Valentine Sims', 'John Grove', 'Richard Marriot', 'William Cooke', 'Robert Allot', 'Nathaniel Butter', 'Thomas Dring Junior', 'John Browne ', 'F Burton', 'William Aspley', 'Andrew Crooke', 'Thomas Archer', 'Humphrey Moseley', 'Henry Rockit']\n"
     ]
    }
   ],
   "source": [
    "'''Catalog authors, grams, and TCPIDs'''\n",
    "file = '/Users/amycweng/Digital Humanities/Early-Modern-London/playwrightsTCP.csv'\n",
    "tcpIDs = ngrams.keys()\n",
    "auths = authors(file, tcpIDs)\n",
    "uniqueAuths = []\n",
    "for TCPID,infoList in auths.items():\n",
    "    uniqueAuths.extend(infoList[0])\n",
    "uniqueAuths = list(set(uniqueAuths))\n",
    "print(len(uniqueAuths))\n",
    "print(uniqueAuths)\n",
    "\n",
    "pubdf = pd.read_csv('spreadsheet_Plays_PublishersTCP.csv')\n",
    "textToPub = {}\n",
    "uniquePubs = []\n",
    "for idx,TCPID in enumerate(pubdf['id']):\n",
    "    pubs = pubdf['editedpublisher'][idx]\n",
    "    if pubs == 'None': continue\n",
    "    pubs = pubs.split('; ')\n",
    "    for i,p in enumerate(pubs):\n",
    "        pubs[i] = p.strip() \n",
    "        uniquePubs.append(p)\n",
    "    textToPub[TCPID] = pubs\n",
    "uniquePubs = list(set(uniquePubs))\n",
    "print(len(uniquePubs))\n",
    "print(uniquePubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "aToGramText = {}\n",
    "authGrams = {}\n",
    "\n",
    "# authpubedges stores all possible Author-Author, Author-Publisher, Publisher-Publisher edges\n",
    "authpubedges = []\n",
    "\n",
    "for TCPID, infoList in auths.items(): \n",
    "    allList = infoList[0].copy()\n",
    "    if TCPID in textToPub.keys():\n",
    "        allList.extend(textToPub[TCPID])\n",
    "    combos = list(combinations(allList,2))\n",
    "    for combo in combos: \n",
    "        if combo[1] == combo[0]: continue #avoids edges that point back to self \n",
    "        if (combo[1],combo[0]) in authpubedges: continue\n",
    "        if (combo[0],combo[1]) in authpubedges: continue\n",
    "        authpubedges.append(combo)\n",
    "\n",
    "    for auth in infoList[0]: \n",
    "        auth = auth.strip(r'\\[').strip(r'\\]')\n",
    "        if auth not in authGrams.keys():\n",
    "            authGrams[auth] = []\n",
    "        authGrams[auth].extend(list(set(ngrams[TCPID]))) \n",
    "        if auth not in aToGramText.keys(): \n",
    "            aToGramText[auth] = {TCPID: list(set(ngrams[TCPID]))}\n",
    "        else: aToGramText[auth] = aToGramText[auth] | {TCPID: list(set(ngrams[TCPID]))}\n",
    "\n",
    "gramToAuths = {}\n",
    "for auth, grams in authGrams.items(): \n",
    "    for gram in grams: \n",
    "        if gram not in gramToAuths.keys(): gramToAuths[gram] = [auth]\n",
    "        else: gramToAuths[gram].append(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Color Legend: \n",
    "- author nodes are purple \n",
    "- publisher nodes are palevioletred\n",
    "- ngram edges are pink\n",
    "- aut-pub edges are light blue #80B1D3 \n",
    "- aut-aut edges are light purple #bebada\n",
    "- put-pub edges are light green #ccebc5\n",
    "'''\n",
    "\n",
    "def gramAuthEdges(gramAuthDict):\n",
    "    '''\n",
    "    Catalogs edges (as well as the edge value, i.e., n-gram) between nodes\n",
    "    Returns a list of tuples (combo,gram) \n",
    "    '''\n",
    "    edgelist = []    \n",
    "    for gram,authList in gramAuthDict.items():\n",
    "        combos = list(combinations(authList,2))\n",
    "        for combo in combos: \n",
    "            # add only edges between DIFFERENT authors. For each different gram, add a new edge  \n",
    "            if combo[1] == combo[0]: continue #avoids edges that point back to self \n",
    "            if ((combo[1],combo[0]),gram) in edgelist: continue\n",
    "            if ((combo[0],combo[1]),gram) in edgelist: continue\n",
    "            edgelist.append((combo,gram))  \n",
    "    return edgelist\n",
    "\n",
    "'''Creates the information that will pop-up when a cursor hovers over an author node in the network'''\n",
    "def createTitle(auth,authInfo):\n",
    "    items = ''\n",
    "    for TCPID,gramList in authInfo.items(): \n",
    "        count = 0\n",
    "        for item in gramList: \n",
    "            if count == 0: gramString = f'{item}'\n",
    "            count += 1 \n",
    "            if not count % 2: \n",
    "                if count == len(gramList): gramString += f', {item}'\n",
    "                else: gramString += f', {item},\\n'\n",
    "            elif count>1: gramString += f'\\t{item}'\n",
    "        items += f'{TCPID}: {gramString}\\n'\n",
    "    title = f'{auth}:\\n{items}'\n",
    "    return title\n",
    "    \n",
    "def gramGraph(edgelist,title,heading,aToGramText):\n",
    "    # Create pyvis graph\n",
    "    aa, ap, pp = 0,0,0\n",
    "    g = Network(width=800,height=1000,notebook=True,heading=heading,bgcolor='white',font_color='black',directed=True)\n",
    "    for authPair,gram in edgelist:        \n",
    "        a1Title = createTitle(authPair[0],aToGramText[authPair[0]])\n",
    "        a2Title = createTitle(authPair[1],aToGramText[authPair[1]])\n",
    "        g.add_node(authPair[0], authPair[0], title=a1Title, color='purple',labelHighlightBold=True,chosen=True)\n",
    "        g.add_node(authPair[1], authPair[1], title=a2Title, color='purple',labelHighlightBold=True,chosen=True)\n",
    "        if gram != None: \n",
    "            g.add_edge(authPair[0],authPair[1],title=gram,color='pink',width=5,arrows='hide')\n",
    "    \n",
    "    for p1,p2 in authpubedges:\n",
    "        if p1 in uniqueAuths: \n",
    "            g.add_node(p1, p1, title=p1, color='purple',labelHighlightBold=True,chosen=True)\n",
    "            p1role = 'auth'\n",
    "        else: \n",
    "            g.add_node(p1, p1, title=p1, color='palevioletred',labelHighlightBold=True,chosen=True)\n",
    "            p1role = 'pub'\n",
    "        if p2 in uniqueAuths: \n",
    "            g.add_node(p2, p2, title=p2, color='purple',labelHighlightBold=True,chosen=True)\n",
    "            p2role = 'auth'\n",
    "        else: \n",
    "            g.add_node(p2, p2, title=p2, color='palevioletred',labelHighlightBold=True,chosen=True)\n",
    "            p2role = 'pub'\n",
    "        if (p1role == 'auth' and p2role == 'pub') or (p1role == 'pub' and p2role == 'auth'):\n",
    "            g.add_edge(p1,p2,color='#80B1D3',width=5,arrows='hide')\n",
    "            ap += 1\n",
    "        elif (p1role == 'auth' and p2role == 'auth'): \n",
    "            g.add_edge(p1,p2,color='#bebada',width=5,arrows='hide')\n",
    "            aa += 1\n",
    "        else: \n",
    "            g.add_edge(p1,p2,color='#ccebc5',width=5,arrows='hide')\n",
    "            pp += 1\n",
    "    print(f'There are {aa} author-author edges, {ap} author-publisher edges, and {pp} publisher-publisher edges.')\n",
    "    g.set_edge_smooth('dynamic')\n",
    "    g.repulsion()\n",
    "    g.show(title+\".html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 105 n-gram edges\n"
     ]
    }
   ],
   "source": [
    "'''Create and output network'''\n",
    "gaEdges = gramAuthEdges(gramToAuths)\n",
    "print(f'There are {len(gaEdges)} n-gram edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n",
      "There are 12 author-author edges, 44 author-publisher edges, and 7 publisher-publisher edges.\n"
     ]
    }
   ],
   "source": [
    "gramGraph(gaEdges,'spreadsheet plays network','Spreadsheet Plays - Network',aToGramText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get context windows for n-grams'''\n",
    "import os,re\n",
    "\n",
    "def getTexts(folder):\n",
    "    fileToText = {}\n",
    "    underscores = {}\n",
    "    for root,dirs,files in os.walk(folder):\n",
    "        for file in files:\n",
    "                if '.txt' not in file: continue\n",
    "                path = os.path.join(folder,file)\n",
    "                f = open(path,'r')\n",
    "                text = f.readlines()[0]\n",
    "                if '_' in file: \n",
    "                        name = file.split('_')[0]\n",
    "                        if name not in underscores.keys(): \n",
    "                                underscores[name] = text\n",
    "                        else: \n",
    "                                underscores[name] = underscores[name] + ' ' + text\n",
    "                else: \n",
    "                        name = file.split('.')[0]\n",
    "                        fileToText[name] = text\n",
    "                f.close()\n",
    "    for name,text in underscores.items():\n",
    "        fileToText[name] = text\n",
    "    return fileToText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "'''Map n-grams to TCPIDs'''\n",
    "bigramdata = getTexts('/Users/amycweng/Digital Humanities/playsTXT')\n",
    "\n",
    "textGrams = {}\n",
    "for TCPID in ngrams.keys(): \n",
    "    nGrams = list(set(ngrams[TCPID]))\n",
    "    if '_' in TCPID: \n",
    "        TCPID = TCPID.split('_')[0]\n",
    "    textGrams[TCPID] = []\n",
    "    for gram in nGrams: \n",
    "        gram = re.sub('_',' ',gram)\n",
    "        textGrams[TCPID].append(gram)\n",
    "print(len(textGrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(searchgram,textName):\n",
    "    text = bigramdata[textName]\n",
    "    if (searchgram in text):\n",
    "        indices = [i for i in range(len(text)) if text.startswith(searchgram, i)]\n",
    "        windows = []\n",
    "        for index in indices:\n",
    "            if index > 120: window = text[(index-120):(index+120)].split(' ')\n",
    "            else: window = text[:index+120].split(' ')\n",
    "            del window[0]\n",
    "            del window[-1]\n",
    "            window = ' '.join(window)\n",
    "            windows.append(window)\n",
    "        return windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get context windows into a dictionary'''\n",
    "contexts = {}\n",
    "for TCPID,gramList in textGrams.items():\n",
    "    contexts[TCPID] = {}\n",
    "    for gram in gramList: \n",
    "        formatGram = re.sub(' ','_',gram)\n",
    "        contexts[TCPID][formatGram] = context(gram,TCPID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"playsNgramContexts.txt\",\"w+\") as file: \n",
    "    for tcpid, cDict in contexts.items(): \n",
    "        file.write(f'{tcpid}:\\n')\n",
    "        for gram,cList in cDict.items(): \n",
    "            file.write(f'{gram}:\\n')\n",
    "            for c in cList: \n",
    "                file.write(f'{c}\\n')\n",
    "            file.write('\\n\\n')\n",
    "        file.write('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
