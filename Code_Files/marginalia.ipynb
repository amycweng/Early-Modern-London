{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bar(orientation,data,title,color,labels):\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    if orientation == 'horizontal': \n",
    "        plt.barh(data[0],data[1],color=color)\n",
    "    else: \n",
    "        plt.bar(data[0],data[1],color=color)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.xlabel(labels[0], fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.ylabel(labels[1], fontsize=15)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def wordcloud(counts, title): \n",
    "    word_cloud = WordCloud(background_color = \"white\", width=3000, height=2000, max_words=500, collocations=True).generate_from_frequencies(counts)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title,fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 files.\n",
      "Processed 20 files.\n",
      "Processed 30 files.\n",
      "Processed 40 files.\n",
      "Processed 50 files.\n",
      "Processed 60 files.\n",
      "Processed 70 files.\n",
      "Possibly missing abbreviations:  Counter({'apoc': 15, 'c': 15, 'l': 10, 'cap': 9, 'fur': 8, 'chap': 7, 'io': 7, 'sirac': 7, 'ibid': 6, 'trist': 5, 'ma': 4, 'wisd': 4, 'amor': 4, 'sal': 4, 'trinum': 4, 'heaut': 4, 'vers': 4, 'v': 4, 'thyest': 4, 'amph': 4, 'med': 4, 'q': 3, 'a': 3, 'apo': 3, 'sai': 3, 'capt': 3, 'tom': 3, 'stich': 3, 'pont': 3, 'thy': 3, 'exerc': 3, 'agam': 3, 'sa': 3, 'part': 3, 'octav': 3, 'adelph': 3, 'cum': 3, 'esal': 2, 'pseud': 2, 'pers': 2, 'm': 2, 'apc': 2, 'n': 2, 'in': 2, 'dut': 2, 'irem': 2, 'trucul': 2, 't': 2, 'var': 2, 'ter': 2, 'ponto': 2, 'rud': 2, 'mostell': 2, 'eun': 2, 'tibull': 2, 'controv': 2, 'point': 2, 'hippol': 2, 'hosca': 2, 'micha': 2, 'paris': 2, 'art': 2, 'timo': 2, 'troad': 2, 'esd': 2, 'truc': 2, 'thren': 2, 'merc': 2, 'curcul': 2, 'serm': 2, 'reg': 2, 'car': 2, 'lib': 2, 'verse': 2, 'er': 2, 'paral': 2, 'oed': 2, 'troa': 1, 'totu': 1, 'habr': 1, 'horat': 1, 'sapient': 1, 'mostel': 1, 'trin': 1, 'cat': 1, 'u': 1, 'acs': 1, 'ebr': 1, 'uc': 1, 'mtih': 1, 'peld': 1, 'fohn': 1, 'ibn': 1, 'eb': 1, 'iubn': 1, 'ia': 1, 'eps': 1, 'odip': 1, 'd': 1, 'stih': 1, 'ius': 1, 'ot': 1, 'esni': 1, 'phorm': 1, 'ls': 1, 'r': 1, 'psol': 1, 'hcb': 1, 'icr': 1, 'march': 1, 'trimum': 1, 'ovid': 1, 'sum': 1, 'cotrov': 1, 'hilip': 1, 'i': 1, 'chi': 1, 'tam': 1, 'mas': 1, 'toh': 1, 'phi': 1, 'ose': 1, 'iof': 1, 'par': 1, 'ler': 1, 'osh': 1, 'lon': 1, 'cro': 1, 'hst': 1, 'make': 1, 'obser': 1, 'obseru': 1, 'ca': 1, 'host': 1, 'amo': 1, 'ark': 1, 'he': 1, 'hest': 1, 'prev': 1, 'frov': 1, 'at': 1, 'hester': 1, 'ver': 1, 'ct': 1, 'say': 1, 'to': 1, 'salomon': 1, 'totum': 1, 'oum': 1, 'exek': 1, 'lue': 1, 'gan': 1, 'esr': 1, 'mac': 1, 'oedipod': 1, 'disp': 1, 'aphor': 1, 'cassin': 1, 'sanct': 1, 'asin': 1, 'problem': 1, 'aphrodis': 1, 'rudent': 1, 'macc': 1, 'wisdom': 1, 'temp': 1, 'mattb': 1, 'amphitr': 1, 'beautont': 1, 'tibul': 1, 'erem': 1, 'beaut': 1, 'abakk': 1, 'thoss': 1, 'mostest': 1, 'aulul': 1, 'eleg': 1, 'pnt': 1, 'iams': 1, 'b': 1, 'cles': 1, 's': 1, 'glor': 1, 'ou': 1, 'ibidem': 1, 'aul': 1, 'most': 1, 'poen': 1, 'bacch': 1, 'probl': 1, 'lip': 1, 'hil': 1, 'hbr': 1, 'tu': 1, 'gell': 1, 'adelp': 1, 'sdr': 1, 'syrac': 1, 'phrm': 1, 'iosu': 1, 'maith': 1, 'alul': 1, 'cn': 1, 'leg': 1, 'lm': 1, 'ones': 1, 'thyst': 1, 'oedipd': 1, 'gam': 1, 'ha': 1, 'et': 1, 'san': 1, 'sap': 1, 'anhol': 1, 'idyll': 1, 'pol': 1, 'nec': 1, 'geo': 1, 'iorem': 1, 'marcus': 1, 'sim': 1, 'cron': 1, 'aug': 1, 'fsai': 1, 'quaest': 1, 'carum': 1, 'oedip': 1, 'cas': 1, 'lamnt': 1, 'tss': 1, 'hesh': 1, 'maccab': 1, 'namb': 1, 'iho': 1, 'mtam': 1, 'iib': 1, 'eccls': 1, 'match': 1, 'eecles': 1, 'mag': 1})\n"
     ]
    }
   ],
   "source": [
    "from bibleMarginalia import *\n",
    "from getTexts import * \n",
    "# EP: /Users/amycweng/Digital Humanities/eebotcp/texts\n",
    "# TCP: /Users/amycweng/Digital Humanities/TCP \n",
    "\n",
    "csv_data = pd.read_csv('/Users/amycweng/Digital Humanities/sermons.csv')\n",
    "tcpIDs = [ _ for _ in csv_data['id']]\n",
    "\n",
    "all_specials = []\n",
    "for idx, tcpID in enumerate(tcpIDs): \n",
    "    path = findTextTCP(tcpID)\n",
    "    notes, specials = getMarginalia(path)\n",
    "    for case in specials: \n",
    "        all_specials.append(case.split(' ')[0])\n",
    "    with open(f'/Users/amycweng/Digital Humanities/charityMargin/{tcpID}NOTES.txt','w') as file: \n",
    "        for note in notes[0]: \n",
    "            file.write(f'{note}\\n')\n",
    "    if len(notes[1]) > 0: \n",
    "        print(f'Outlier formatting for {tcpID}: ', notes[1])\n",
    "    if (idx+1) % 10 == 0 and idx != 0: \n",
    "        print(f'Processed {idx+1} files.')\n",
    "print('Possibly missing abbreviations: ', Counter(all_specials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charity_citations import * \n",
    "\n",
    "all_notes = []\n",
    "all_books = []\n",
    "all_chapters = []\n",
    "charity_margin = {}\n",
    "all_margin = {}\n",
    "\n",
    "folder = '/Users/amycweng/Digital Humanities/charityMargin'\n",
    "for notesfile in os.listdir(folder): \n",
    "    tcpID = notesfile.split('NOTES')[0]\n",
    "    charity_margin[tcpID] = []\n",
    "\n",
    "    notesfile = open(f'{folder}/{notesfile}','r')\n",
    "    notes = [note.strip('\\n') for note in notesfile.readlines()]\n",
    "    notesfile.close()\n",
    "\n",
    "    all_notes.extend(notes)\n",
    "    all_margin[tcpID] = notes\n",
    "    for n in notes:             \n",
    "        if n in bible_charity: \n",
    "            charity_margin[tcpID].append(n)\n",
    "        book = n.split(' ')\n",
    "        if book[0] == '1' or book[0] == '2': \n",
    "            all_books.append(f'{book[0]} {book[1]}')\n",
    "            chapter = book[2].split(':')[0]\n",
    "            all_chapters.append(f'{book[0]} {book[1]} {chapter}')\n",
    "        else: \n",
    "            all_books.append(book[0])\n",
    "            chapter = book[1].split(':')[0]\n",
    "            all_chapters.append(f'{book[0]} {chapter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charity_citations_file = open(f'marginalia.charity.sermons.txt','w')\n",
    "all_citations_file = open(f'marginalia.all.sermons.txt','w')\n",
    "for tcpID, margin in charity_margin.items(): \n",
    "    charity_citations_file.write(f'{tcpID} -- {\"; \".join(margin)}\\n')\n",
    "    all_citations_file.write(f'{tcpID} -- {\"; \".join(all_margin[tcpID])}\\n')\n",
    "charity_citations_file.close()\n",
    "all_citations_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_counts = Counter(all_books).most_common(n=25)\n",
    "print(book_counts)\n",
    "x,y = [],[]\n",
    "for word,freq in book_counts: \n",
    "    x.append(word)\n",
    "    y.append(freq)\n",
    "bar('horizontal',(x,y),'Most Commonly Cited Biblical or Apocryphal Books in the Marginalia of the Charity Sermons Dataset','darkblue',('Book','Frequency'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_counts = Counter(all_chapters)\n",
    "print(chapter_counts.most_common(n=25))\n",
    "wordcloud(chapter_counts,'Biblical or Apocryphal Chapters in the Marginalia of the Charity Sermons Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_counts = Counter(all_notes)\n",
    "print(passage_counts.most_common(n=25))\n",
    "wordcloud(passage_counts,'Biblical or Apocryphal Passages in the Marginalia of the Charity Sermons Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTestament = ['Matthew', 'Mark', 'Luke', 'John','Acts','Romans','1 Corinthians','2 Corinthians','Galatians','Ephesians','Philippians','Colossians','1 Thessalonians','2 Thessalonians','1 Timothy','2 Timothy','Titus','Philemon','Hebrews','James','1 Peter','2 Peter','1 John', '2 John','3 John','Jude','Revelation']\n",
    "oldTestament = ['Genesis','Exodus','Leviticus','Numbers','Deuteronomy','Joshua','Judges','Ruth','1 Samuel','2 Samuel','1 Kings','2 Kings','1 Chronicles','2 Chronicles','Ezra','Nehemiah','Esther','Job','Psalms','Proverbs','Ecclesiastes','Canticles','Isaiah','Jeremiah','Lamentations','Ezekiel','Daniel','Hosea','Joel','Amos','Obadiah','Jonah','Micah','Nahum','Habakkuk','Zephaniah','Haggai','Zechariah','Malachi']\n",
    "\n",
    "newTcount, oldTcount = 0,0\n",
    "\n",
    "book_counts = dict(Counter(all_books))\n",
    "for book, count in book_counts.items(): \n",
    "    if book in newTestament: \n",
    "        newTcount += count \n",
    "    elif book in oldTestament: \n",
    "        oldTcount += count\n",
    "print(f'New T {newTcount} and Old T {oldTcount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_charity = []\n",
    "for c_list in charity_margin.values():\n",
    "    all_charity.extend(c_list)\n",
    "print(f'There are {len(all_charity)} citations of charity-related passages.')\n",
    "charity_counts = dict(Counter(all_charity))\n",
    "print('Lines cited only once: ', [line for line, freq in charity_counts.items() if freq == 1])\n",
    "charity_counts = sorted([(line, freq) for line, freq in charity_counts.items() if freq > 1],key=lambda k: (k[1], k[0]))\n",
    "x,y = [],[]\n",
    "for word,freq in charity_counts: \n",
    "    x.append(word)\n",
    "    y.append(freq)\n",
    "bar('horizontal',(x,y),'Biblical Passages on Charity in the Marginalia of the Charity Sermons Dataset','palevioletred',('Frequency','Passage'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
