{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getTexts import *\n",
    "import pandas as pd \n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('/Users/amycweng/Digital Humanities/sermons.csv')\n",
    "tcpIDs = [ _ for _ in csv_data['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTexts(folder,search):\n",
    "    texts = {}\n",
    "    for file in os.listdir(folder):\n",
    "        if 'NOTES' not in file: \n",
    "            name = file.split('.')[0]\n",
    "            if name in search: \n",
    "                path = os.path.join(folder,file)\n",
    "                with open(path,'r') as file: \n",
    "                    data = file.readlines()\n",
    "                if len(data) != 0: \n",
    "                    texts[name] = data[0]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "sermons = getTexts('/Users/amycweng/Digital Humanities/charityTXT',tcpIDs)\n",
    "# sermons = getTexts('/Users/amycweng/Digital Humanities/charityTXT','A01523')\n",
    "print(len(sermons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ['A01523', 'A01528', 'A10027']\n"
     ]
    }
   ],
   "source": [
    "words = ['charity','charitable','alm','bequest',\n",
    "        'poor','rate','usury','usurer','bequeath',\n",
    "        'money','beneficence','poverty','credit',\n",
    "        'creditor','loan','lend','new','novel','novelty',\n",
    "        'wealth','profit','profitable','beneficial',\n",
    "        'commodity','thrift','thrifty','industry','bullion',\n",
    "        'talon','talent','beggar','needy','bestow',\n",
    "        'liberality','giving','penny','liberal',\n",
    "        'shilling','score','restitution','default',\n",
    "        'halfpenny','quarter','ounce','broker',\n",
    "        'debtor','debt']\n",
    "sus = []\n",
    "for tcpID, text in sermons.items(): \n",
    "    if not re.search('charity|caritas|charitable|\\balm\\b|\\balmes\\b|poor|poor man|poverty|money|needy|hungry|beggar|taxation', text): \n",
    "        sus.append(tcpID)\n",
    "print(len(sus), sus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract the entire body text from an XML document.  \n",
    "'''\n",
    "outputfolder = 'charityTXT'\n",
    "convert(tcpIDs,outputfolder)\n",
    "print(underscores)\n",
    "convert(underscores,outputfolder)\n",
    "\n",
    "'''\n",
    "TCP charity texts that are not in EP: \n",
    "'B33867', 'B13871', 'B13868', 'B13878', 'B13862', 'B13860', \n",
    "'B09696', 'A86972', 'A19579', 'A09957'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns = [\"Preach't at (.*?)[^\\w\\s\\-]\",'Preached at (.*?)[^\\w\\s\\-]','preached at (.*?)[^\\w\\s\\-]','preached in (.*?)[^\\w\\s\\-\\']']\n",
    "patterns1 = [\"preach't (.*?)$\",\"preached at (.*?)$\",\"preached in (.*?)$\",\"preacht (.*?)$\",\"before the (.*?)$\", \"before his (.*?)$\"]\n",
    "patterns2 = [\"preacher at (.*?)$\",\"preacher in (.*?)$\",\"pastor at (.*?)$\",\"pastor of (.*?)$\"]\n",
    "places = []\n",
    "pastorPlaces = []\n",
    "import csv\n",
    "\n",
    "outFile = open(f'sermons_locations.csv','a+')\n",
    "columns = ['id','title','author','date','location']\n",
    "writer = csv.DictWriter(outFile, fieldnames=columns)\n",
    "writer.writeheader()\n",
    "\n",
    "located = []\n",
    "for idx, title in enumerate(csv_data['title']):\n",
    "    foundPattern1 = False\n",
    "    for pattern in patterns1: \n",
    "        place = re.search(rf'{pattern}', title)\n",
    "        if place: \n",
    "            # places.append(place.group())\n",
    "            dict = {'id': tcpIDs[idx], \n",
    "                    'title': title,\n",
    "                    'author': csv_data['author'][idx],\n",
    "                    'date': csv_data['date'][idx],\n",
    "                    'location': place.group()\n",
    "                    }\n",
    "            located.append(tcpIDs[idx])\n",
    "            writer.writerow(dict)\n",
    "            # print(f'{tcpIDs[idx]}: {place.group()}')\n",
    "            foundPattern1 = True\n",
    "            break\n",
    "    if not foundPattern1: \n",
    "        for pattern in patterns2: \n",
    "            place = re.search(rf'{pattern}', title)\n",
    "            if place: \n",
    "                dict = {'id': tcpIDs[idx], \n",
    "                    'title': title,\n",
    "                    'author': csv_data['author'][idx],\n",
    "                    'date': csv_data['date'][idx],\n",
    "                    'location': place.group()\n",
    "                }\n",
    "                # pastorPlaces.append(place.group())\n",
    "                located.append(tcpIDs[idx])\n",
    "                writer.writerow(dict)\n",
    "                foundPattern2 = True\n",
    "                break\n",
    "\n",
    "for idx, tcpID in enumerate(tcpIDs):\n",
    "    if tcpID in located: \n",
    "        continue\n",
    "    dict = {'id': tcpID, \n",
    "            'title': csv_data['title'][idx],\n",
    "            'author': csv_data['author'][idx],\n",
    "            'date': csv_data['date'][idx],\n",
    "            'location': ''\n",
    "            }\n",
    "    writer.writerow(dict)\n",
    "\n",
    "# print(len(places), len(pastorPlaces), len(places)+len(pastorPlaces))\n",
    "# print(places)\n",
    "# print(pastorPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTextTCP(id):\n",
    "    if re.match('B1|B4',id[0:2]):\n",
    "        path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    else: \n",
    "        if f'{id}.P4.xml' in os.listdir(f'{TCP}/P1{id[0:2]}'):\n",
    "            path = f'{TCP}/P1{id[0:2]}/{id}.P4.xml'\n",
    "        elif f'{id}.P4.xml' in os.listdir(f'{TCP}/P2{id[0:2]}'): \n",
    "            path = f'{TCP}/P2{id[0:2]}/{id}.P4.xml'\n",
    "    return path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extracting title pages directly from TCP. \n",
    "Title pages often contain information about where the sermon was preached. \n",
    "'''\n",
    "import csv \n",
    "folder = f'/Users/amycweng/Digital Humanities/'\n",
    "outfile = open(f'{folder}/sermon_titles.csv','a+')\n",
    "columns = ['id','title page']\n",
    "writer = csv.DictWriter(outfile, fieldnames=columns)\n",
    "writer.writeheader()\n",
    "\n",
    "tcpIDs = ['A65610','A15015']\n",
    "for tcpID in tcpIDs: \n",
    "    path = findTextTCP(tcpID)\n",
    "    with open(path,'r') as file: \n",
    "        data = file.read()\n",
    "    tag = SoupStrainer(\"div1\", attrs={'type':'title page'})\n",
    "    soup = BeautifulSoup(data,parse_only=tag,features='html.parser')\n",
    "    title = []\n",
    "    sentences = soup.find_all('p')\n",
    "    for sentence in sentences: \n",
    "        title.append(sentence.text)\n",
    "    if len(title) != 0: \n",
    "        title = ' '.join(title)\n",
    "        title = re.sub('\\n',' ',title)\n",
    "        t = re.search(r'^(.*?) \\d{4}',title)\n",
    "        if t: \n",
    "            writer.writerow({'id': tcpID,  'title page': t.group()})\n",
    "        else: \n",
    "            writer.writerow({'id': tcpID,  'title page': title})\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
