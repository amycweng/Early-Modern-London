{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getTexts import *\n",
    "import pandas as pd \n",
    "import re \n",
    "\n",
    "def getTexts(folder,search):\n",
    "    texts = {}\n",
    "    for file in os.listdir(folder):\n",
    "        if 'NOTES' not in file: \n",
    "            name = file.split('.')[0]\n",
    "            if name in search: \n",
    "                path = os.path.join(folder,file)\n",
    "                with open(path,'r') as file: \n",
    "                    data = file.readlines()\n",
    "                if len(data) != 0: \n",
    "                    texts[name] = data[0]\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "csv_data = pd.read_csv('/Users/amycweng/Digital Humanities/sermons.csv')\n",
    "tcpIDs = [ _ for _ in csv_data['id']]\n",
    "sermons = getTexts('/Users/amycweng/Digital Humanities/charityTXT',tcpIDs)\n",
    "print(len(sermons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {0: 'charity|charitable', \n",
    "        1: 'beneficience|bequeath|bestow|liberality|benevolence|goodwill| alm | almes |kindness|almsdeed',\n",
    "        2: 'poor|poverty|rich|wealthy|wealth|beggar|orphan|needy|labourer|impotent|bankrup|penury|meanness|prosperity|bounty',\n",
    "        3: 'rate|usury|usurer|money|commodity|talon|talent|coin|bullion|exchange|shilling|farthing| pound |penny|purchase',\n",
    "        4: 'credit|creditor|loan|lend',\n",
    "        5: ' debt|debtor|borrow|pledge|pawn',\n",
    "        6: 'industry|industrious|thrift|labor|labour|occupation|profit|profitable|commodious',\n",
    "        7: 'prison|imprisonment',\n",
    "        8: 'hospital|almshouse|orphanage',\n",
    "        9: 'city|citizen|london'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A02549 favour the sin be personal the call free which may be and be manage by other with all humble sociableness hospital frugality conscionable improvement of all mean and opportunity to the good of god church i may not yet dissemble that while we plead the divine right of episcopacy a double scandal be take by man otherwise not unjudicious and\n"
     ]
    }
   ],
   "source": [
    "tcpID = 'A02549'\n",
    "t = sermons[tcpID] \n",
    "t = t.split(' ')\n",
    "indices = []\n",
    "for idx, word in enumerate(t):\n",
    "    toContinue = False\n",
    "    # if re.match(rf'{groups[0]}|{groups[1]}|{groups[2]}|{groups[8]}|{groups[7]}',word):  \n",
    "    if re.match(rf'{groups[8]}',word):  \n",
    "        for i in indices:\n",
    "            if idx in range(i-20,i+40):\n",
    "                toContinue = True\n",
    "        if not toContinue: \n",
    "            indices.append(idx)\n",
    "            print(tcpID, ' '.join(t[idx-20:idx+40]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tcpID, t in sermons.items():\n",
    "    count = 0 \n",
    "    t = sermons[tcpID] \n",
    "    t = t.split(' ')\n",
    "    for idx, word in enumerate(t):\n",
    "        if re.match(rf'{groups[8]}',word):  \n",
    "            count += 1 \n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract the entire body text from an XML document.  \n",
    "'''\n",
    "outputfolder = 'charityTXT'\n",
    "convert(tcpIDs,outputfolder)\n",
    "print(underscores)\n",
    "convert(underscores,outputfolder)\n",
    "\n",
    "'''\n",
    "TCP charity texts that are not in EP: \n",
    "'B33867', 'B13871', 'B13868', 'B13878', 'B13862', 'B13860', \n",
    "'B09696', 'A86972', 'A19579', 'A09957'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns = [\"Preach't at (.*?)[^\\w\\s\\-]\",'Preached at (.*?)[^\\w\\s\\-]','preached at (.*?)[^\\w\\s\\-]','preached in (.*?)[^\\w\\s\\-\\']']\n",
    "patterns1 = [\"preach't (.*?)$\",\"preached at (.*?)$\",\"preached in (.*?)$\",\"preacht (.*?)$\",\"before the (.*?)$\", \"before his (.*?)$\"]\n",
    "patterns2 = [\"preacher at (.*?)$\",\"preacher in (.*?)$\",\"pastor at (.*?)$\",\"pastor of (.*?)$\"]\n",
    "places = []\n",
    "pastorPlaces = []\n",
    "import csv\n",
    "\n",
    "outFile = open(f'sermons_locations.csv','a+')\n",
    "columns = ['id','title','author','date','location']\n",
    "writer = csv.DictWriter(outFile, fieldnames=columns)\n",
    "writer.writeheader()\n",
    "\n",
    "located = []\n",
    "for idx, title in enumerate(csv_data['title']):\n",
    "    foundPattern1 = False\n",
    "    for pattern in patterns1: \n",
    "        place = re.search(rf'{pattern}', title)\n",
    "        if place: \n",
    "            # places.append(place.group())\n",
    "            dict = {'id': tcpIDs[idx], \n",
    "                    'title': title,\n",
    "                    'author': csv_data['author'][idx],\n",
    "                    'date': csv_data['date'][idx],\n",
    "                    'location': place.group()\n",
    "                    }\n",
    "            located.append(tcpIDs[idx])\n",
    "            writer.writerow(dict)\n",
    "            # print(f'{tcpIDs[idx]}: {place.group()}')\n",
    "            foundPattern1 = True\n",
    "            break\n",
    "    if not foundPattern1: \n",
    "        for pattern in patterns2: \n",
    "            place = re.search(rf'{pattern}', title)\n",
    "            if place: \n",
    "                dict = {'id': tcpIDs[idx], \n",
    "                    'title': title,\n",
    "                    'author': csv_data['author'][idx],\n",
    "                    'date': csv_data['date'][idx],\n",
    "                    'location': place.group()\n",
    "                }\n",
    "                # pastorPlaces.append(place.group())\n",
    "                located.append(tcpIDs[idx])\n",
    "                writer.writerow(dict)\n",
    "                foundPattern2 = True\n",
    "                break\n",
    "\n",
    "for idx, tcpID in enumerate(tcpIDs):\n",
    "    if tcpID in located: \n",
    "        continue\n",
    "    dict = {'id': tcpID, \n",
    "            'title': csv_data['title'][idx],\n",
    "            'author': csv_data['author'][idx],\n",
    "            'date': csv_data['date'][idx],\n",
    "            'location': ''\n",
    "            }\n",
    "    writer.writerow(dict)\n",
    "\n",
    "# print(len(places), len(pastorPlaces), len(places)+len(pastorPlaces))\n",
    "# print(places)\n",
    "# print(pastorPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extracting title pages directly from TCP. \n",
    "Title pages often contain information about where the sermon was preached. \n",
    "'''\n",
    "import csv \n",
    "folder = f'/Users/amycweng/Digital Humanities/'\n",
    "outfile = open(f'{folder}/sermon_titles.csv','a+')\n",
    "columns = ['id','title page']\n",
    "writer = csv.DictWriter(outfile, fieldnames=columns)\n",
    "writer.writeheader()\n",
    "\n",
    "tcpIDs = ['A65610','A15015']\n",
    "for tcpID in tcpIDs: \n",
    "    path = findTextTCP(tcpID)\n",
    "    with open(path,'r') as file: \n",
    "        data = file.read()\n",
    "    tag = SoupStrainer(\"div1\", attrs={'type':'title page'})\n",
    "    soup = BeautifulSoup(data,parse_only=tag,features='html.parser')\n",
    "    title = []\n",
    "    sentences = soup.find_all('p')\n",
    "    for sentence in sentences: \n",
    "        title.append(sentence.text)\n",
    "    if len(title) != 0: \n",
    "        title = ' '.join(title)\n",
    "        title = re.sub('\\n',' ',title)\n",
    "        t = re.search(r'^(.*?) \\d{4}',title)\n",
    "        if t: \n",
    "            writer.writerow({'id': tcpID,  'title page': t.group()})\n",
    "        else: \n",
    "            writer.writerow({'id': tcpID,  'title page': title})\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
