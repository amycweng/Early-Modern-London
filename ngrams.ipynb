{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import pandas as pd\n",
    "from gensim.models import Phrases, phrases\n",
    "\n",
    "def getTexts(folder):\n",
    "    texts = {}\n",
    "    for file in os.listdir(folder):\n",
    "        if 'NOTES' not in file: \n",
    "                name = file.split('.')[0]\n",
    "                path = os.path.join(folder,file)\n",
    "                f = open(path,'r')\n",
    "                data = f.readlines()\n",
    "                if len(data) != 0: \n",
    "                    texts[name] = data[0]\n",
    "                    f.close()\n",
    "    return texts\n",
    "\n",
    "def getgrams(txt):\n",
    "    infile = open(txt,'r')\n",
    "    lines = infile.readlines()\n",
    "    infile.close()\n",
    "    allgrams = []\n",
    "    for line in lines: \n",
    "        line = line.split(':')\n",
    "        ngrams = line[1].strip()\n",
    "        if '_' in ngrams: \n",
    "                ngrams = ngrams.strip().split(' ')\n",
    "                for n in ngrams:\n",
    "                        allgrams.append(n)\n",
    "        else: continue\n",
    "    return allgrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    }
   ],
   "source": [
    "bigramdata = getTexts('/Users/amycweng/Digital Humanities/charityTXT')\n",
    "bigramtexts = list(bigramdata.values())\n",
    "bigramnames = list(bigramdata.keys())\n",
    "print(len(bigramnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram model trained\n",
      "trigram model trained\n"
     ]
    }
   ],
   "source": [
    "training = []\n",
    "for t in bigramtexts:\n",
    "    words = t.split(' ')\n",
    "    training.append(words)\n",
    "\n",
    "bigrammodel = Phrases(training, min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('bigram model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trigram model trained\n"
     ]
    }
   ],
   "source": [
    "trigrammodel = Phrases(bigrammodel[training], min_count=2, threshold= 0, scoring='npmi', connector_words=phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "print('trigram model trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 files processed\n",
      "40 files processed\n",
      "60 files processed\n",
      "80 files processed\n",
      "100 files processed\n",
      "120 files processed\n",
      "140 files processed\n",
      "160 files processed\n",
      "180 files processed\n",
      "processing complete\n"
     ]
    }
   ],
   "source": [
    "searchwords = ['charity', 'charitie','charities','charitable','alms','almsgiving',\n",
    "                'bequest','bequests','alm','provisions','poor','poverty','impouerished',\n",
    "                'pouerty','pouertie','povertie','rates','rating','vagrant','vagrancy',\n",
    "                'vagrants','caritas','profit','profits','talents','talent']\n",
    "gramDict = {}\n",
    "gramFreqs = {}\n",
    "for key in searchwords: \n",
    "    gramDict[key] = []\n",
    "    gramFreqs[key] = 0\n",
    "    \n",
    "name = 'charity'\n",
    "storeGramFile = open(f'gramsEach{name}Text.txt','w')\n",
    "count = 0\n",
    "for idx, text in enumerate(bigramtexts):\n",
    "    #for outputting to txt file, specify here\n",
    "    textGrams = []\n",
    "    text = text.strip().split(' ')\n",
    "    bgcount = Counter(b for b in bigrammodel[text] if len(b.split(\"_\")) > 1)\n",
    "    tgcount = Counter(t for t in trigrammodel[text] if len(t.split(\"_\")) > 2)\n",
    "    for gram,freq in dict(bgcount).items():\n",
    "        for s in searchwords: \n",
    "            if s in gram.split('_'):\n",
    "                gramDict[s].append(gram)\n",
    "                gramFreqs[s] += freq\n",
    "                textGrams.append(gram)\n",
    "\n",
    "    storeGramFile.write(f'{bigramnames[idx]}: {\" \".join(textGrams)}\\n')\n",
    "    count += 1\n",
    "    if count%20 == 0:\n",
    "        print(count, \"files processed\")\n",
    "storeGramFile.close()\n",
    "with open(f'{name}Grams.txt', 'w+') as outfile: \n",
    "    for s in searchwords: \n",
    "        outfile.write(f\"{s}: {gramFreqs[s]} occurrences\\n\\t\\t{' '.join(gramDict[s])}\\n\")\n",
    "\n",
    "print('processing complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
