{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv, os,re\n",
    "import pandas as pd \n",
    "authSearch = 'Perkins, William, 1558-1602.'\n",
    "\n",
    "# pubSearch = 'Nathanael Butter|Nathaniel Butter|Nathaniell Butter|Nat Butter|Nath Butter|Nathnaiell sic Butter|N Butter|N athaniel Butter|Na Butter|Nathnaiell sic Butter|N athaniel Butter|Nathanaell Butter'\n",
    "# pubSearchAuth = 'Butter, Nathaniel, d. 1664, publisher.|Butter, Nicholas, d. 1664, publisher.|Butter, Nathaniel, d. 1664, bookseller.'\n",
    "# name = 'butter'\n",
    "\n",
    "pubSearch = 'Elizabeth Allde|E lizabeth Allde|E lizabeth A llde|Hanna Barret|widow|Widow'\n",
    "name = 'women'\n",
    "\n",
    "outFile = open(f'{name}TCP.csv','a+')\n",
    "columns = ['id','title','author','publisher','pubplace','keywords','date']\n",
    "writer = csv.DictWriter(outFile, fieldnames=columns)\n",
    "writer.writeheader()\n",
    "count = 0\n",
    "tcpIDs = []\n",
    "for csvFile in os.listdir('TCP metadata'):\n",
    "    data = pd.read_csv(os.path.join('TCP metadata',csvFile))\n",
    "    for idx,entry in enumerate(data['publisher']):\n",
    "        found = False\n",
    "        if re.search(pubSearch,str(entry)):\n",
    "            found = True\n",
    "        if re.search(pubSearchAuth, data['author'][idx]):\n",
    "            found = True\n",
    "        if found: \n",
    "            names = entry.split('; ')\n",
    "            names = '; '.join(list(set(names)))\n",
    "            count += 1\n",
    "            row = {'id':data['id'][idx],\n",
    "                    'title':data['title'][idx],\n",
    "                    'author':data['author'][idx],\n",
    "                    'publisher':data['publisher'][idx],\n",
    "                    'pubplace':data['pubplace'][idx],\n",
    "                    'keywords':data['keywords'][idx],\n",
    "                    'date':data['date'][idx]}\n",
    "            writer.writerow(row)\n",
    "            found = False\n",
    "print(str(count)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os,re,shutil\n",
    "perkins = pd.read_csv('perkinsTCP.csv')\n",
    "perkinsIDs = perkins['id']\n",
    "count = 0\n",
    "for id in perkinsIDs:\n",
    "    if re.match('B1|B4',id[0:2]):\n",
    "        if f'{id}.P4.xml' in os.listdir(f'TCP/P2{id[0:2]}'): \n",
    "            path = f'TCP/P2{id[0:2]}/{id}.P4.xml'\n",
    "            found = True\n",
    "        else: found = False\n",
    "    else: \n",
    "        if f'{id}.P4.xml' in os.listdir(f'TCP/P1{id[0:2]}'):\n",
    "            path = f'TCP/P1{id[0:2]}/{id}.P4.xml'\n",
    "            found = True\n",
    "        elif f'{id}.P4.xml' in os.listdir(f'TCP/P2{id[0:2]}'): \n",
    "            path = f'TCP/P2{id[0:2]}/{id}.P4.xml'\n",
    "            found = True\n",
    "        else: found = False\n",
    "    if found: shutil.copy(path,f'/Users/amycweng/Digital Humanities/perkins')\n",
    "    else: print(f'{id} not found')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
